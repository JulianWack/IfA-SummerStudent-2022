{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1139c3",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Seek to find the largest value of k up to which linear theory gives accurate results. Such value for kmax is found for each density bin separately. We use Markov Chain Monte Carlo to fit $b1$ and $\\beta$. To assert if linear theory is accurate, we compare the inferred $f_0*\\sigma_8$ to the true one.\n",
    "\n",
    "The fitting process is layed out in `Fit_b1_beta_MCMC.ipynb`. Here we use the mock covariance matrix.\n",
    "\n",
    "For the simple model at hand, the multipoles can be computed analytically via\n",
    "$$\n",
    "P_{\\ell}(k) = \\int_{-1}^{1} \\frac{2\\ell+1}{2} L_{\\ell}(\\mu) P^{model}(k,\\mu) d\\mu, \\quad P^{model}(k,\\mu) = (1+\\beta \\mu^2)^2b_1^2P^{matter}_{lin}(k) \\exp{(-\\frac{1}{2}(\\sigma k \\mu)^2)}.\n",
    "$$\n",
    "where $P^{model}(k,\\mu)$ denotes the redshift space power spectrum.\n",
    "\n",
    "The simplest model is the linear Kaiser law: $P^{model}(k,\\mu) = (1+\\beta \\mu^2)^2b_1^2P^{matter}_{lin}(k)$, leading to:\n",
    "$$\n",
    "\\begin{align}\n",
    "    P_0(k) = (1 + \\frac{2}{3}\\beta + \\frac{1}{5}\\beta^2 ) b_1^2 P_{lin}(k) \\\\\n",
    "    P_2(k) = (\\frac{4}{3}\\beta + \\frac{4}{7}\\beta^2) b_1^2 P_{lin}(k).\n",
    "\\end{align}\n",
    "$$\n",
    "When including a FoG term:\n",
    "$$\n",
    "\\begin{align}\n",
    "    P_0(k) = \\frac{1}{2 k^5 \\sigma ^5} \\left(\\sqrt{2 \\pi } \\text{erf}\\left(\\frac{k \\sigma }{\\sqrt{2}}\\right) \\left(3 \\beta ^2+k^4 \\sigma ^4+2 \\beta  k^2 \\sigma ^2\\right)+e^{-\\frac{1}{2} k^2 \\sigma ^2} \\left(-2 \\beta  (\\beta +2) k^3 \\sigma ^3-6 \\beta ^2 k \\sigma \\right)\\right) b_1^2 P_{lin}(k) \\\\\n",
    "    P_2(k) = -\\frac{5}{4 k^7 \\sigma ^7} \\left(\\sqrt{2 \\pi } \\text{erf}\\left(\\frac{k \\sigma }{\\sqrt{2}}\\right) \\left(-45 \\beta ^2+k^6 \\sigma ^6+(2 \\beta -3) k^4 \\sigma ^4+3 (\\beta -6) \\beta  k^2 \\sigma ^2\\right) \\\\\n",
    "    +e^{-\\frac{1}{2} k^2 \\sigma ^2}\\left(2 (2 \\beta  (\\beta +2)+3) k^5 \\sigma ^5+12 \\beta  (2 \\beta +3) k^3 \\sigma ^3+90 \\beta ^2 k \\sigma \\right) \\right) b_1^2 P_{lin}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d2f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d549cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import legendre, erf\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import inv_cov_funcs as icf\n",
    "import cat_power_algos as catpk\n",
    "import classylss\n",
    "import fitsio\n",
    "import zeus \n",
    "from nbodykit.lab import *\n",
    "from nbodykit import style\n",
    "plt.style.use(style.notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0698097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwack/.conda/envs/nbodykit-env/lib/python3.8/site-packages/nbodykit/cosmology/cosmology.py:427: UserWarning: Class did not read input parameter(s): sigma_8\n",
      "  self.engine = ClassEngine(pars)\n"
     ]
    }
   ],
   "source": [
    "LOS = [0,0,1]\n",
    "redshift = 0\n",
    "BoxSize = 2000\n",
    "cosmo_paras = classylss.load_ini('/home/jwack/main/Planck18_LCDM.ini')\n",
    "cosmo = cosmology.cosmology.Cosmology.from_dict(cosmo_paras)\n",
    "Plin = cosmology.LinearPower(cosmo, redshift, transfer='CLASS')\n",
    "sigma8_lin = Plin.sigma8\n",
    "sigma8_true = 0.8111 \n",
    "f0_true = cosmo.scale_independent_growth_rate(redshift)\n",
    "\n",
    "dk = 0.01\n",
    "ells = [0,2]\n",
    "damped = True # choice of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857874e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load computed power spectra to deduce multipoles in each bin and P(k,mu) from data\n",
    "k_full, shotnoise, n_ptile, Pk_ells_full = icf.load_power_data('/home/jwack/main/fitmodel_densitysplit/', \n",
    "                                                               ells, get_data_Pkmus=False)\n",
    "# for given BoxSize, k is NaN above 0.034\n",
    "possible_kmax = k_full[k_full<=0.343][1:] # ignore first k bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b112ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum entropy priors\n",
    "\n",
    "# def logprior(theta, mean_guess, damped):\n",
    "#     ''' The natural logarithm of the prior probability. From pre-analysis step obtained an estimate of the parameter mean values\n",
    "#     s.t. the maximum entropy prior is the exponential distribution. No value could be estimated for FoG parameter, hence\n",
    "#     uniform prior.\n",
    "#     Assume parameters independent such that log priors add. When damped is True, also fit FoG parameter.\n",
    "#     Note that normalization is irrelevant for MCMC.'''\n",
    "#     lp = 0.\n",
    "#     b1_mean, beta_mean = mean_guess\n",
    "#     if damped:\n",
    "#         b1, beta, sigma = theta\n",
    "#         sigma_min, sigma_max = 1, 5\n",
    "#         lp_sigma = 0. if sigma_min < sigma < sigma_max else -np.inf\n",
    "#     else:\n",
    "#         b1, beta = theta\n",
    "#         lp_sigma = 0\n",
    "        \n",
    "#     lp_b1 = -b1/np.abs(b1_mean) if b1 > 0 else -np.inf\n",
    "#     if beta_mean > 0:\n",
    "#         lp_beta = -beta/beta_mean if beta > 0 else -np.inf\n",
    "#     else:\n",
    "#         lp_beta = -beta/beta_mean if beta < 0 else -1e6#-np.inf\n",
    "        \n",
    "#     return lp_b1 + lp_beta + lp_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eccb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprior(theta, i, kmax, damped):\n",
    "    ''' The natural logarithm of the prior probability. Assume parameters independent such that log priors add.\n",
    "    When damped is True, also fit FoG parameter\n",
    "    Note that normalization is irrelevant for MCMC.'''\n",
    "    lp = 0.\n",
    "    if damped:\n",
    "        b1, beta, sigma = theta\n",
    "        sigma_min, sigma_max = 1, 5\n",
    "        sigma_max = 5 if kmax < 0.12 else 30\n",
    "        lp_sigma = 0. if sigma_min < sigma < sigma_max else -np.inf\n",
    "    else:\n",
    "        b1, beta = theta\n",
    "        lp_sigma = 0\n",
    "        \n",
    "    b1_min, b1_max = 0, 3\n",
    "    if i == 0:\n",
    "        beta_min, beta_max = -3, 3\n",
    "    else:\n",
    "        beta_min, beta_max = 0, 3\n",
    "        \n",
    "    lp_b1 = 0. if b1_min < b1 < b1_max else -np.inf\n",
    "    lp_beta = 0. if beta_min < beta < beta_max else -np.inf\n",
    "    \n",
    "    return lp_b1 + lp_beta + lp_sigma\n",
    "\n",
    "\n",
    "def loglike(theta, data_multipoles, k, C_inv, damped):\n",
    "    '''Return logarithm of likelihood i.e. -0.5*chi2.\n",
    "    data_multipoles must be an array of shape (len(ells), len(k)). theta is parameter vector: [b1, beta, sigma].'''\n",
    "    ells = [0,2]\n",
    "    model_multipoles = np.empty((len(ells), len(k)))\n",
    "\n",
    "    if damped:\n",
    "        b1, beta, sigma = theta\n",
    "        model_multipoles[0] = ( 1/(2*(k*sigma)**5) * (np.sqrt(2*np.pi)*erf(k*sigma/np.sqrt(2))*(3*beta**2+(k*sigma)**4+2*beta*(k*sigma)**2) + \n",
    "                                                    np.exp(-0.5*(k*sigma)**2)*(-2*beta*(beta+2)*(k*sigma)**3-6*beta**2*k*sigma) ) ) * b1**2 * Plin(k)\n",
    "        model_multipoles[1] = ( -5/(4*(k*sigma)**7) * (np.sqrt(2*np.pi)*erf(k*sigma/np.sqrt(2))*(-45*beta**2+(k*sigma)**6+(2*beta-3)*(k*sigma)**4+3*(beta-6)*beta*(k*sigma)**2) + \n",
    "                                                    np.exp(-0.5*(k*sigma)**2)*((4*beta*(beta+2)+6)*(k*sigma)**5+12*beta*(2*beta+3)*(k*sigma)**3+90*beta**2*k*sigma) ) ) * b1**2 * Plin(k)\n",
    "    else:\n",
    "        b1, beta = theta\n",
    "        model_multipoles[0] = (1 + 2/3*beta + 1/5*beta**2) * b1**2 * Plin(k)\n",
    "        model_multipoles[1] = (4/3*beta + 4/7*beta**2) * b1**2 * Plin(k)\n",
    "\n",
    "    D_M = (data_multipoles - model_multipoles).flatten()\n",
    "    \n",
    "    return -0.5*D_M@(C_inv @ D_M)\n",
    "\n",
    "\n",
    "def logpost(theta, i, data_multipoles, k, C_inv, damped):\n",
    "    '''Returns the logarithm of the posterior. By Bayes' theorem, this is just the sum of the log prior and log likelihood (up \n",
    "    to a irrelavant constant).\n",
    "    Uses values for theta from pre-analysis step to inform prior\n",
    "    ''' \n",
    "    return logprior(theta, i, k[-1], damped) + loglike(theta, data_multipoles, k, C_inv, damped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b36b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting up to kmax=0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:28<00:00, 86.49it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:35<00:00, 70.97it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 76.03it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:31<00:00, 79.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 77.41it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.72it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:36<00:00, 68.13it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.46it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:17<00:00, 32.44it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:04<00:00, 38.53it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:28<00:00, 28.14it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:46<00:00, 53.65it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [04:27<00:00,  9.34it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:27<00:00, 28.63it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:59<00:00, 41.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:25<00:00, 29.26it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [02:03<00:00, 20.22it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [02:50<00:00, 14.67it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [03:04<00:00, 13.58it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:32<00:00, 26.97it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:44<00:00, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 0-th percentile in 0:28:04.804251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:26<00:00, 93.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 81.09it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:46<00:00, 54.22it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:40<00:00, 61.40it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:17<00:00, 32.17it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 76.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:37<00:00, 67.39it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:12<00:00, 34.33it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 55.33it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:59<00:00, 41.88it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:29<00:00, 28.06it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:35<00:00, 69.85it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.00it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:45<00:00, 23.74it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:41<00:00, 60.02it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:44<00:00, 56.35it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:43<00:00, 57.71it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:13<00:00, 33.97it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.38it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 54.85it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 58.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 1-th percentile in 0:17:55.472689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:31<00:00, 80.06it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 76.27it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 77.50it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 77.05it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 76.66it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:39<00:00, 62.90it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:47<00:00, 52.40it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:47<00:00, 53.06it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 54.55it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:49<00:00, 50.22it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:35<00:00, 69.67it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:35<00:00, 69.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:00<00:00, 41.59it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:44<00:00, 56.82it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:21<00:00, 30.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:40<00:00, 24.92it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:47<00:00, 52.14it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [03:12<00:00, 12.96it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:05<00:00, 38.23it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:55<00:00, 45.18it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:56<00:00, 44.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 2-th percentile in 0:19:26.605178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:26<00:00, 93.49it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 90.04it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:29<00:00, 85.87it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 82.52it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:34<00:00, 71.45it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 77.83it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:33<00:00, 75.24it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 55.24it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:40<00:00, 61.19it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:53<00:00, 46.51it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:50<00:00, 49.26it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:39<00:00, 63.01it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:48<00:00, 51.89it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.87it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:05<00:00, 38.18it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:39<00:00, 62.85it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:00<00:00, 41.54it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.48it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:51<00:00, 48.34it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 54.93it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 58.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 3-th percentile in 0:14:52.737030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 91.55it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 89.53it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.13it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 80.92it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:34<00:00, 72.93it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 81.31it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:49<00:00, 50.53it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:31<00:00, 78.54it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:04<00:00, 38.95it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:38<00:00, 64.49it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:58<00:00, 42.80it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:18<00:00, 31.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:44<00:00, 56.70it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:38<00:00, 65.37it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:51<00:00, 48.25it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:38<00:00, 64.41it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:04<00:00, 38.86it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.70it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:46<00:00, 53.67it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 54.99it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:48<00:00, 51.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 4-th percentile in 0:15:45.437257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 91.36it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 90.24it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:37<00:00, 67.20it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:29<00:00, 86.02it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 81.59it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:34<00:00, 72.95it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:34<00:00, 71.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:43<00:00, 58.11it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:36<00:00, 68.79it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:37<00:00, 25.72it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:40<00:00, 61.17it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:05<00:00, 38.44it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:43<00:00, 57.97it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:50<00:00, 49.80it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:48<00:00, 51.03it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:41<00:00, 60.19it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:04<00:00, 39.01it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:43<00:00, 56.91it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:40<00:00, 61.82it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:47<00:00, 52.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 5-th percentile in 0:15:35.633880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 81.95it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:29<00:00, 83.53it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:28<00:00, 86.87it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:31<00:00, 79.00it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 80.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 81.76it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:32<00:00, 77.80it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 55.05it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:38<00:00, 64.77it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 58.52it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:37<00:00, 66.21it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:35<00:00, 71.26it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:41<00:00, 60.84it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 58.21it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:40<00:00, 62.08it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [01:00<00:00, 41.29it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.94it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:46<00:00, 54.33it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:42<00:00, 59.24it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:44<00:00, 55.69it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:45<00:00, 55.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 6-th percentile in 0:13:49.664323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:27<00:00, 91.39it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:30<00:00, 83.13it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:31<00:00, 79.54it/s]\n",
      "Sampling progress : 100%|███████████████████████████████████████████████████████████| 2500/2500 [00:29<00:00, 83.53it/s]\n",
      "Sampling progress :  89%|████████████████████████████████████████████████████▊      | 2237/2500 [00:27<00:03, 85.40it/s]"
     ]
    }
   ],
   "source": [
    "# set range of kmax for which we compute delta_fs8 for each density bin. \n",
    "# exclude taking lowested k bin as kmax since that bin will be removed in slicing (negative quadrupole)\n",
    "kmax_range = possible_kmax[:21]\n",
    "Nkmax = len(kmax_range)\n",
    "\n",
    "chains = np.empty((n_ptile, Nkmax), dtype='object')\n",
    "\n",
    "b1_fits, beta_fits, sigma_fits, delta_fs8 = np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan) \n",
    "b1_stds, beta_stds, sigma_stds, delta_fs8_stds = np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan), np.full((n_ptile, Nkmax), np.nan)\n",
    "reduced_chi2 = np.full((n_ptile, Nkmax), np.nan)\n",
    "\n",
    "nsteps = 2500\n",
    "\n",
    "if damped == True:\n",
    "    ndim = 3\n",
    "    nwalkers = 8 \n",
    "#     b1_guesses = np.loadtxt('fit_prep/b1_guess_damped.txt')\n",
    "#     beta_guesses = np.loadtxt('fit_prep/beta_guess_damped.txt')\n",
    "    start_b1 = 0.5 + 1*np.random.random(nwalkers)\n",
    "    start_beta = 0.5 + 1*np.random.random(nwalkers)\n",
    "    start_sigma = 1 + 4*np.random.random(nwalkers) \n",
    "    start = np.column_stack([start_b1, start_beta, start_sigma])\n",
    "else:\n",
    "    ndim = 2\n",
    "    nwalkers = 6 \n",
    "#     b1_guesses = np.loadtxt('fit_prep/b1_guess.txt')\n",
    "#     beta_guesses = np.loadtxt('fit_prep/beta_guess.txt')\n",
    "    start_b1 = 0.5 + 1*np.random.random(nwalkers)\n",
    "    start_beta = 0.5 + 1*np.random.random(nwalkers)\n",
    "    start = np.column_stack([start_b1, start_beta])\n",
    "\n",
    "\n",
    "print(\"Fitting up to kmax=%.3f\"%kmax_range[-1])\n",
    "\n",
    "for i in range(n_ptile):\n",
    "    cov_mat = np.loadtxt('/home/jwack/main/bruteforce_covmat/covariance_matricies/cov_ptile_%d.txt'%i)\n",
    "    t1 = time.time()\n",
    "    for j,kmax in enumerate(kmax_range):\n",
    "        # slice up to increasingly large kmax and find delta_fs8 for each bin\n",
    "        mask = np.full(len(k_full), False)\n",
    "        mask = k_full <= kmax\n",
    "        mask[0] = False \n",
    "        k_sliced = k_full[mask]\n",
    "        Pk_ells_i = Pk_ells_full[:,:,mask][i]\n",
    "        C_inv = icf.mock_cov_mat_inv(cov_mat, k_full, kmax)\n",
    "        \n",
    "#         guesses = [b1_guesses[i][j], beta_guesses[i][j]]\n",
    "        sampler = zeus.EnsembleSampler(nwalkers, ndim, logpost, maxiter=1e5, verbose=False, args=[i, Pk_ells_i, k_sliced, C_inv, damped]) \n",
    "        sampler.run_mcmc(start, nsteps)\n",
    "        \n",
    "        chain = sampler.get_chain(flat=True, discard=nsteps//2)\n",
    "        chains[i][j] = chain # only needed when wanting to investigate chains later on\n",
    "        \n",
    "        b1_fits[i][j], b1_stds[i][j] = np.mean(chain[:,0]), np.std(chain[:,0]) \n",
    "        # parameter space is sym about b1=0 for Kaiser model. To get non negative fs8 assure that b1 and beta have the same sign\n",
    "        if i == 0:\n",
    "            b1_fits[i][j] *= -1\n",
    "        beta_fits[i][j], beta_stds[i][j] = np.mean(chain[:,1]), np.std(chain[:,1])\n",
    "        delta_fs8[i][j] = 1 - sigma8_lin*(beta_fits[i][j]*b1_fits[i][j])/(f0_true*sigma8_true)\n",
    "        delta_fs8_stds[i][j] = np.abs(sigma8_lin/(f0_true*sigma8_true)*(beta_stds[i][j]*b1_fits[i][j]+beta_fits[i][j]*b1_stds[i][j]))        \n",
    "        if damped:\n",
    "            sigma_fits[i][j], sigma_stds[i][j] = np.mean(chain[:,2]), np.std(chain[:,2])\n",
    "            reduced_chi2[i][j] = -2*loglike([b1_fits[i][j], beta_fits[i][j], sigma_fits[i][j]], Pk_ells_i, k_sliced, C_inv, damped) / (len(ells)*len(k_sliced)-ndim)\n",
    "        else:\n",
    "            reduced_chi2[i][j] = -2*loglike([b1_fits[i][j], beta_fits[i][j]], Pk_ells_i, k_sliced, C_inv, damped) / (len(ells)*len(k_sliced)-ndim)\n",
    "            \n",
    "    t2 = time.time()\n",
    "    print('Fitted %d-th percentile in %s'%(i,str(timedelta(seconds=t2-t1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data\n",
    "if damped:\n",
    "    root_path = 'fit_results/FoG/'\n",
    "    np.savetxt(root_path+'sigma_fits.txt', sigma_fits)\n",
    "    np.savetxt(root_path+'sigma_stds.txt', sigma_stds)\n",
    "else:\n",
    "    root_path = 'fit_results/NoFoG/'\n",
    "\n",
    "np.savetxt(root_path+'b1_fits.txt', b1_fits)\n",
    "np.savetxt(root_path+'b1_stds.txt', b1_stds)\n",
    "\n",
    "np.savetxt(root_path+'beta_fits.txt', beta_fits)\n",
    "np.savetxt(root_path+'beta_stds.txt', beta_stds)\n",
    "\n",
    "np.savetxt(root_path+'delta_fs8.txt', delta_fs8)\n",
    "np.savetxt(root_path+'delta_fs8_stds.txt', delta_fs8_stds)\n",
    "\n",
    "np.savetxt(root_path+'reduced_chi2.txt', reduced_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a4c2a",
   "metadata": {},
   "source": [
    "Repeat computation for full (not density binned) power spectrum. Since the mock covariance matrix was only computed for individual density bins, we use Gaussian covariance with Pkmu inferred from the data. See eq 24 of Grieb et al. 2016: https://arxiv.org/pdf/1509.04293.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15475dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_delta_fs8, full_delta_fs8_stds = np.full(Nkmax, np.nan), np.full(Nkmax, np.nan)\n",
    "\n",
    "r = FFTPower.load('density_bins/all_bins.json')\n",
    "\n",
    "for i,kmax in enumerate(kmax_range):\n",
    "    mask = np.full(len(k_full), False)\n",
    "    mask = k_full <= kmax\n",
    "    mask[0] = False \n",
    "    k_sliced = k_full[mask]\n",
    "    \n",
    "    Pk_0, Pk_2 = r.poles['power_0'].real-r.attrs['shotnoise'], r.poles['power_2'].real\n",
    "    Pk_ells = np.row_stack([Pk_0, Pk_2])[:,mask]\n",
    "    mus = r.power.coords['mu']\n",
    "    Pkmu_data = (np.outer(Pk_0, legendre(0)(mus)) + np.outer(Pk_2, legendre(2)(mus)))[mask]\n",
    "    \n",
    "    C_inv = icf.gaussian_cov_mat_inv(k_sliced, ells, BoxSize, r.attrs['shotnoise'], 0.01, Pkmu_data, mus)\n",
    "    sampler = zeus.EnsembleSampler(nwalkers, ndim, logpost, maxiter=1e5, verbose=False, args=[-1, Pk_ells, k_sliced, C_inv, damped]) \n",
    "    sampler.run_mcmc(start, nsteps)\n",
    "\n",
    "    chain = sampler.get_chain(flat=True, discard=nsteps//2)\n",
    "\n",
    "    full_delta_fs8[i] = 1 - sigma8_lin*(np.mean(chain[:,1])*np.mean(chain[:,0]))/(f0_true*sigma8_true)\n",
    "    full_delta_fs8_stds[i] = np.abs(sigma8_lin/(f0_true*sigma8_true)*(np.std(chain[:,1])*np.mean(chain[:,0])+np.mean(chain[:,1])*np.std(chain[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c650c2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "for i in range(n_ptile):\n",
    "    plt.plot(kmax_range, delta_fs8[i], label='%d-th'%i)\n",
    "    plt.fill_between(kmax_range, delta_fs8[i]-delta_fs8_stds[i,:], delta_fs8[i]+delta_fs8_stds[i,:], alpha=0.1)\n",
    "    \n",
    "#plt.plot(kmax_range, full_delta_fs8, '--', label='all densities', c='k')\n",
    "#plt.fill_between(kmax_range, full_delta_fs8-full_delta_fs8_stds, full_delta_fs8+full_delta_fs8_stds, color='k', alpha=0.1)\n",
    "    \n",
    "# add 10% diviation lines\n",
    "plt.hlines([-0.1, 0.1], kmax_range[0], kmax_range[-1], linestyle='dotted', color='k', linewidth=2)\n",
    "\n",
    "plt.ylim([-0.3, 1.2])\n",
    "\n",
    "plt.title(r'relative difference to true $f_0*\\sigma_8$')\n",
    "plt.xlabel(r'$k_{max}$')\n",
    "plt.ylabel(r'$1 - \\sigma_8^{lin}*\\beta*b1/(f_0\\sigma_8)^{true}$')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(\"plots/Kaiser_dfs8_vs_kmax.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27924376",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "As observed in previous analysis steps, bins of extreme density are more difficult to fit with such a simple model than the middle density bins. Hence the agreement of fs8 worse for these bins. From a 'by eye' inspection, we find that the 10% accuracy for the middle bins is surpassed at $kmax \\approx 0.06$ the latest. When including a FoG term, this threshold is pushed to slightly larger $kmax$. Regardless of the model, fs8 is typically underestimated for all density and bins. \n",
    "In the Kaiser+FoG model, density bin 9 produces fs8 $\\approx 0$ for $kmax>0.125$. This is due to $\\beta$ being fitted close to zero and $b_1$ not being fitted to a large enough value to compensate.\n",
    "\n",
    "The issue of dealing with negative $\\beta$ being fitted for the lowest density bin is described in `Fit_b1_beta_MCMC.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4856b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(26,18))\n",
    "\n",
    "ax_b1 = plt.subplot(2,3,1)\n",
    "ax_beta = plt.subplot(2,3,2)\n",
    "ax_sigma = plt.subplot(2,3,3)\n",
    "ax_chi2 = plt.subplot(2,3,(4,6))\n",
    "\n",
    "for i in range(n_ptile):\n",
    "    ax_b1.plot(kmax_range, b1_fits[i], label='%d-th'%i)\n",
    "    ax_b1.fill_between(kmax_range, b1_fits[i]-b1_stds[i], b1_fits[i]+b1_stds[i], alpha=0.1)\n",
    "    \n",
    "    ax_beta.plot(kmax_range, beta_fits[i], label='%d-th'%i)\n",
    "    ax_beta.fill_between(kmax_range, beta_fits[i]-beta_stds[i], beta_fits[i]+beta_stds[i], alpha=0.1)\n",
    "    \n",
    "    ax_sigma.plot(kmax_range, sigma_fits[i], label='%d-th'%i)\n",
    "    ax_sigma.fill_between(kmax_range, sigma_fits[i]-sigma_stds[i], sigma_fits[i]+sigma_stds[i], alpha=0.1)\n",
    "    \n",
    "    ax_chi2.plot(kmax_range, reduced_chi2[i], label='%d-th'%i)\n",
    "  \n",
    "ax_b1.set_title('b1 fit')\n",
    "ax_b1.set_xlabel(r'$k_{max}$')\n",
    "ax_b1.set_ylabel(r'$b1$')\n",
    "\n",
    "ax_beta.set_title(r'$\\beta$ fit')\n",
    "ax_beta.set_xlabel(r'$k_{max}$')\n",
    "ax_beta.set_ylabel(r'$\\beta$')\n",
    "\n",
    "ax_sigma.set_title(r'$\\sigma$ fit')\n",
    "ax_sigma.set_xlabel(r'$k_{max}$')\n",
    "ax_sigma.set_ylabel(r'$\\sigma$')\n",
    "\n",
    "ax_chi2.set_title(r'reduced $\\chi^2$')\n",
    "ax_chi2.set_xlabel(r'$k_{max}$')\n",
    "ax_chi2.set_ylabel(r'$\\chi^2 / dof$')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, +0.05), ncol=n_ptile)\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig(\"plots/Kaiser_fits.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb88e8",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Upon comparing this plot to the one produced by `pre-analysis_fit.ipynb` (`parameter_guesses.pdf`) (using fast minimization of chi2 to estimate mean of parameters), we find good agreement in the plots of $b_1$ and $\\beta$. Note that in the analysis, to produce fs8$>0$, we had to invert the sign of $b_1$ for the 0th density bin after fitting (model is symmetric in sign of $b_1$). This causes an apparent difference to `parameter_guesses.pdf` where the guessed value of $b_1$ is positive.\n",
    "\n",
    "As expected, the simple model only works up to small $k_{max}$, illustrated by growing reduced $\\chi^2$.  \n",
    "\n",
    "Note that the FoG term is of form $\\exp(-0.5(\\sigma k \\mu)^2)$ and corrects the Kaiser model by damping it which only occurs for large $k$. For small $k_{max}$ the damping term is approximately 1 for all $\\sigma$, such that the data cannot inform the value of $\\sigma$. This causes the $\\sigma$ posterior to be approximately the same as the prior. Since we choose `Uniform(1,5)` as the prior, the above $\\sigma$ plot is centered on $\\sigma=\\frac{5-1}{2}$ with a standard deviation of $\\sqrt{\\frac{(5-1)^2}{12}} = \\frac{2}{\\sqrt{3}} \\approx 1.15$.\n",
    "Only for $k_{max}>0.1$ it appears that $\\sigma$ can be fitted. Note that the 0th density bin actually reaches the top end of the prior for $k_{max}>0.125$. In `pre-analysis_fit.ipynb` found that for this bin $\\sigma$ increases sharply at $k_{max} = 0.125$ and reaches 30 at $k_{max} = 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chains[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,1.5*ndim))\n",
    "labels = [r'$b1$', r'$\\beta$', r'$\\sigma$']\n",
    "for n in range(ndim):\n",
    "    plt.subplot2grid((ndim, 1), (n, 0))\n",
    "    plt.plot(chain[:,n], alpha=0.5)\n",
    "    plt.ylabel(labels[n])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = zeus.cornerplot(chain.reshape((-1,ndim), order='F'), labels=[r'$b1$', r'$\\beta$', r'$\\sigma$']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbody-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
